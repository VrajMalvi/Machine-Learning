# Reinforcement Learning

Welcome to the "Reinforcement Learning" repository! This repository contains implementations of two popular reinforcement learning algorithms: Thompson Sampling and Upper Confidence Bound (UCB).

## Table of Contents

- [Thompson Sampling](#thompson-sampling)
- [Upper Confidence Bound (UCB)](#upper-confidence-bound-ucb)
- [Introduction](#introduction)
- [Usage](#usage)
- [Results](#results)


## Thompson Sampling

The Thompson Sampling algorithm is a powerful technique used to address the exploration-exploitation trade-off in sequential decision-making problems. In this implementation, Thompson Sampling is applied to optimize the selection of advertisements in an advertising campaign. 

For more details on how Thompson Sampling works and how to use it, please refer to the [Thompson Sampling folder](./Thompson%20Sampling).

## Upper Confidence Bound (UCB)

The Upper Confidence Bound (UCB) algorithm is another widely used reinforcement learning algorithm for solving the multi-armed bandit problem. It balances the trade-off between exploring unknown options and exploiting known options to maximize cumulative rewards.

For more details on how the UCB algorithm works and how to use it, please refer to the [UCB folder](./Upper%20Confidence%20Bound%20(UCB)).

## Introduction

Reinforcement Learning is a subfield of machine learning focused on learning how to make sequential decisions through interactions with an environment. The algorithms implemented here provide solutions to classic problems involving decision-making in uncertain environments.

## Usage

Each algorithm implementation has its own dedicated folder with detailed instructions on usage. To get started with either Thompson Sampling or UCB, follow the usage instructions provided in their respective folders.

## Results

The results of running each algorithm are often visualized to showcase their effectiveness. You can find visualizations and insights in the individual folders for Thompson Sampling and UCB.


